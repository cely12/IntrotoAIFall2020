{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='top'></a>\n",
    "\n",
    "# CSCI 3202, Fall 2020\n",
    "# Assignment 3\n",
    "# Due: Monday 16 November 2020 by 11:59 PM\n",
    "\n",
    "<br> \n",
    "\n",
    "### Your name: Connor Ely\n",
    "\n",
    "<br> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import scipy.integrate as integrate\n",
    "import unittest\n",
    "from math import floor, isclose\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Problem 1:  EVIU and EVPI\n",
    "\n",
    "Suppose we have an overwhelming sense of exam déjà vu, and we're going to catch the Buff Bus again.  We want to decide at what time $d$ to go wait for it.  We decide to use the the linear loss function \n",
    "\n",
    "$$L(d,x)=\\begin{cases} \n",
    "\t2(x-d) & x\\geq d \\\\\n",
    "\t4(d-x) & x <d\n",
    "    \t\\end{cases}$$.\n",
    "        \n",
    "As in the exam, we model the Buff Bus arrival times as an exponential random variable $X$ that arrives on average once per hour, so they have probability density function of $f(x)=e^{-x}$ for $x>0$ (note: this has mean of $E_X[x]=1$).\n",
    "\n",
    "The result from the exam was that the *expected loss* of the decision $d$ was:\n",
    "$$E_X[L(d,x)] = \\int_0^d 4(d-x)e^{-x}\\, dx + \\int_d^\\infty 2(x-d)e^{-x}\\, dx$$\n",
    "\n",
    "...we maybe tried to avoid doing that integral and reasoned through it, because often such an integral is messy and may require numerical methods.\n",
    "\n",
    "\n",
    "### (1a)  A Loss function:\n",
    "\n",
    "Create a `ExpectedLoss` object or function that takes as input 3 arguments: \n",
    "    - a decision $d$\n",
    "    - a loss function $L(d,x)$\n",
    "    - a probability density $f(x)$\n",
    "\n",
    "and returns the value of $$E_X[L(d,x)]=\\int_{-\\infty}^\\infty L(d,x) f(x) \\, dx$$.\n",
    "\n",
    "Inside your function, you can and should use the scipy.integrate function with documentation: \n",
    "https://docs.scipy.org/doc/scipy/reference/tutorial/integrate.html.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExpectedLoss(d, loss_function, prob_density):\n",
    "    return integrate.quad(lambda x: loss_function(d, x)*prob_density(x), 0, d)[0] + integrate.quad(lambda x: loss_function(d, x)*prob_density(x), d, np.inf)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1b) A quick check:\n",
    "Double check that your integrate code is working well on the infinite support of the exponential random variable.  Check that you in fact get $$E[X]=\\int_0^\\infty e^{-x} \\, dx=1$$ from your usage of `integrate` above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integral evaluates to: 1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "f= lambda x:np.exp(-x)\n",
    "L = lambda d, x:1\n",
    "print(\"Integral evaluates to:\", ExpectedLoss(np.inf, L, f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1c) Scoring Decisions:\n",
    "Our goal is typically to compare the losses of 3 decision types:\n",
    " - the decision made \"ignoring uncertainty,\" using $d=E[X]$\n",
    " - the decision made with \"perfect information\", using $d=x$\n",
    " - the decision made with uncertainty to minimize loss, the Bayes' decision.\n",
    " \n",
    "1. Use your function in (1a) to compute the expected loss when ignoring uncertainty.\n",
    "\n",
    "2. Use your function in (1a) or reason to compute the expected loss with perfect information.\n",
    "\n",
    "3. Use your function in (1a) to *plot* the expected loss for a fine grid (`linspace`) of $d$ values from 0 to 10.  Given this plot, visually estimate the optimal decision $d$ and it's expected loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected loss ignoring uncertainty: 2.207276647028654\n",
      "Expected loss with perfect information is zero. All we have to do here is look at the loss function to calculate this when x = d. We don't need to integrate.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1e3b1e50fa0>]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def loss_function(d, x):\n",
    "    if x >= d:\n",
    "        return 2*(x - d)\n",
    "    else:\n",
    "        return 4*(d - x)\n",
    "f= lambda x:np.exp(-x)\n",
    "print(\"Expected loss ignoring uncertainty:\", ExpectedLoss(1, loss_function, f))\n",
    "print(\"Expected loss with perfect information is zero. All we have to do here is look at the loss function to calculate this when x = d. We don't need to integrate.\")\n",
    "x = np.arange(0,10,0.01)\n",
    "d_values = []\n",
    "for i in range(len(x)):\n",
    "    d_values.append(ExpectedLoss(x[i], loss_function, f))\n",
    "plt.plot(x, d_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal decision $d$ seems to be around 0.5 with an expected loss of around 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1d) Optimizing Decisions:\n",
    "Since the Bayes' decision should be the minimum of the function in (1a), we can use another numeric method in Python to find it exactly!  Check out `scipy.optimize` https://docs.scipy.org/doc/scipy/reference/tutorial/optimize.html and use it to find the Bayes' decision.\n",
    "\n",
    "For convenience, you may restructure your code in (1a) to get the loss function while only $d$ as taken as an input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      fun: 1.6218604324327122\n",
      " hess_inv: array([[0.24954617]])\n",
      "      jac: array([-6.40749931e-07])\n",
      "  message: 'Optimization terminated successfully.'\n",
      "     nfev: 14\n",
      "      nit: 6\n",
      "     njev: 7\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([0.40546494])\n",
      "The Bayes' decision is printed as 'fun' in the above table\n"
     ]
    }
   ],
   "source": [
    "outputVariable = minimize(fun = lambda d: ExpectedLoss(d, loss_function, f), x0 = 1.6)\n",
    "print(outputVariable)\n",
    "print(\"The Bayes' decision is printed as 'fun' in the above table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1e) Bigger Losses\n",
    "$$L_l(d,x)=\\begin{cases} \n",
    "\t20(d-x) & x \\leq d \\\\\n",
    "\t200+20(d-x) & x> d \\\\\t\t\n",
    "\t\\end{cases}$$.\n",
    "    \n",
    "Consider instead the loss function above, which contains a large jump at $x=d$.  Use your `ExpectedLoss` and/or `optimize` routines to find the Bayes' decision for the bus-waiting problem in this case, where a large amount of utility is lost as soon as $x>d$ (or we miss the bus).  Does your result here seem intuitive, given the Bayes' decision in parts (1c/1d)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      fun: 46.05179266170881\n",
      " hess_inv: array([[0.05002085]])\n",
      "      jac: array([-4.76837158e-07])\n",
      "  message: 'Optimization terminated successfully.'\n",
      "     nfev: 14\n",
      "      nit: 6\n",
      "     njev: 7\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([2.30258963])\n",
      "The Bayes' decision is printed as 'fun' in the above table\n"
     ]
    }
   ],
   "source": [
    "def nonnegative_loss_function(d, x): #modified loss function, also does not allow for negative loss when x>>>>>d\n",
    "    if x <= d:\n",
    "        if 20*(d-x) > 0:\n",
    "            return 20*(d - x)\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        if 200 + 20*(d-x) > 0:\n",
    "            return 200 + 20*(d - x)\n",
    "        else:\n",
    "            return 0\n",
    "outputVariable2 = minimize(fun = lambda d: ExpectedLoss(d, nonnegative_loss_function, f), x0 = 1.6)\n",
    "print(outputVariable2)\n",
    "print(\"The Bayes' decision is printed as 'fun' in the above table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Bayes' decision value of optimal loss comes out to be a value much higher than previously in part 1d. This makes sense intuitively since now we have much more incentive to arrive earlier since we incur a major loss if we miss the buss. This also means that we incur more loss even arriving at the optimal time since this is earlier than we would have arrived in part 1d."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Problem 2:  Bayesian network to model heart disease\n",
    "\n",
    "The following Bayesian network is based loosely on a study that examined heart disease risk factors in 167 elderly individuals in South Carolina.  Note that this figure uses Y and N to represent Yes and No, whereas in class we used the equivalent T and F to represent True and False Boolean values.\n",
    "\n",
    "<img src=\"http://www.cs.colorado.edu/~tonyewong/home/resources/hw05_bayesnet_heartdisease.png\" style=\"width: 650px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='p1a'></a>\n",
    "\n",
    "### (2a) \n",
    "\n",
    "Create a `BayesNet` object to model this.  Below are the codes for the (conditional) probability `P` function and `BayesNode` class as well, that we used in class on Monday (9 March) to represent the variable nodes and calculate probabilities. You can code this however you want, subject to the following constraints:\n",
    "1. the nodes are represented using the `BayesNode` class and can work with the `P` function for probabilities,\n",
    "1. your `BayesNet` structure keeps track of which nodes are in the Bayes net, as well as\n",
    "1. which nodes are the parents/children of which other nodes.\n",
    "\n",
    "Some *suggested* skeleton codes for a class structure are given. You are free and encouraged to use the code from our in-class notebooks on Bayes Nets and Markov Models. The point of this exercise is to make sure you understand the example from class. The suggestions for methods to implement are in view of the fact that we will need to calculate some probabilities, which is going to require us to `find_node`s and `find_values` that nodes can take on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For the sake of brevity...\n",
    "T, F = True, False\n",
    "\n",
    "## From class:\n",
    "def P(var, value, evidence={}):\n",
    "    '''The probability distribution for P(var | evidence), \n",
    "    when all parent variables are known (in evidence)'''\n",
    "    if len(var.parents)==1:\n",
    "        # only one parent\n",
    "        row = evidence[var.parents[0]]\n",
    "    else:\n",
    "        # multiple parents\n",
    "        row = tuple(evidence[parent] for parent in var.parents)\n",
    "    return var.cpt[row] if value else 1-var.cpt[row]\n",
    "\n",
    "## Also from class:\n",
    "class BayesNode:\n",
    "    \n",
    "    def __init__(self, name, parents, values, cpt):\n",
    "        if isinstance(parents, str):\n",
    "            parents = parents.split()\n",
    "            \n",
    "        if len(parents)==0:\n",
    "            # if no parents, empty dict key for cpt\n",
    "            cpt = {(): cpt}\n",
    "        elif isinstance(cpt, dict):\n",
    "            # if there is only one parent, only one tuple argument\n",
    "            if cpt and isinstance(list(cpt.keys())[0], bool):\n",
    "                cpt = {(v): p for v, p in cpt.items()}\n",
    "\n",
    "        self.variable = name\n",
    "        self.parents = parents\n",
    "        self.cpt = cpt\n",
    "        self.values = values\n",
    "        self.children = []\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return repr((self.variable, ' '.join(self.parents)))    \n",
    "\n",
    "    \n",
    "##===============================================##\n",
    "## Suggested codes for a BayesNet class ##\n",
    "##===============================================##\n",
    "\n",
    "class BayesNet:\n",
    "    '''Bayesian network containing only boolean-variable nodes.'''\n",
    "\n",
    "    def __init__(self, node_specs=[]):\n",
    "        '''Initialize the Bayes net by adding each of the nodes,\n",
    "        which should be a list BayesNode class objects ordered\n",
    "        from parents to children (`top` to `bottom`, from causes\n",
    "        to effects)'''\n",
    "        self.nodes = []\n",
    "        self.variables = []\n",
    "        for node_spec in node_specs:\n",
    "            self.add(*node_spec)\n",
    "                \n",
    "    def add(self, name, parents, values, cpt):\n",
    "        '''Add a new BayesNode to the BayesNet. The parents should all\n",
    "        already be in the net, and the variable itself should not be'''\n",
    "        node = BayesNode(name=name, parents=parents, values=values, cpt=cpt)\n",
    "        assert node.variable not in self.variables\n",
    "        assert all((parent in self.variables) for parent in node.parents)\n",
    "        self.nodes.append(node)\n",
    "        self.variables.append(node.variable)\n",
    "        for parent in node.parents:\n",
    "            self.find_node(parent).children.append(node)\n",
    "\n",
    "    def find_node(self, var):\n",
    "        '''Find and return the BayesNode in the net with name `var`'''\n",
    "        for n in self.nodes:\n",
    "            if n.variable == var:\n",
    "                return n\n",
    "        raise Exception(\"No such variable: {}\".format(var))\n",
    "\n",
    "    def find_values(self, var):\n",
    "        '''Return the set of possible values for variable `var`'''\n",
    "        varnode = self.find_node(var)\n",
    "        return varnode.values\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return 'BayesNet({})'.format(self.nodes)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Bayes net with those nodes and connections\n",
    "heartDiseaseNet = BayesNet([\n",
    "    ('SmokingAndAlcohol', '', [T,F], 0.2),\n",
    "    ('ModerateExercise', '', [T,F], 0.5),\n",
    "    ('HighBloodPressure', ['SmokingAndAlcohol', 'ModerateExercise'], [T,F], {(T, T): 0.6, (T, F): 0.72, (F, T): 0.33, (F, F): 0.51}),\n",
    "    ('Atherosclerosis', '', [T,F], 0.53),\n",
    "    ('FamilyHistory', '', [T,F], 0.15),\n",
    "    ('HeartDisease', ['Atherosclerosis', 'HighBloodPressure', 'FamilyHistory'], [T,F], {(T, T, T): 0.92, (T, T, F): 0.91, (T, F, T): 0.81, (T, F, F): 0.77, (F, T, T): 0.75, (F, T, F): 0.69, (F, F, T): 0.38, (F, F, F): 0.23}),\n",
    "    ('AnginaPectoris', 'HeartDisease', [T,F], {T: 0.85, F: 0.40}),\n",
    "    ('RapidHeartbeats', 'HeartDisease', [T,F], {T: 0.99, F: 0.30})\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "examNet = BayesNet([\n",
    "    ('A', '', [T,F], 0.3),\n",
    "    ('B', '', [T,F], 0.6),\n",
    "    ('C', 'A', [T,F], {T: 0.6, F: 0.30}),\n",
    "    ('D', ['A', 'B'], [T,F], {(T, T): 0.4, (T, F): 0.5, (F, T): 0.1, (F, F): 0.2}),\n",
    "    ('E', ['B', 'D'], [T,F], {(T, T): 0.2, (T, F): 0.3, (F, T): 0.5, (F, F): 0.9})\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{True: 0.7741935483870968, False: 0.22580645161290325}\n",
      "{True: 0.4721739130434783, False: 0.5278260869565218}\n"
     ]
    }
   ],
   "source": [
    "ex = get_prob(X='A', e={'B': T, 'C': T, 'D':T, 'E':T}, bn=examNet)\n",
    "print(ex.prob)\n",
    "ex1 = get_prob(X='C', e={'D':T}, bn=examNet)\n",
    "print(ex1.prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tests_Problem2(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.p1 = BayesNode('p1', '', [T,F], 0.3)\n",
    "        self.p2 = BayesNode('p2', '', [T,F], 0.6)\n",
    "        self.c  = BayesNode('c', ['p1', 'p2'], [T,F], {(T,T):0.1, (T,F):0.2, (F,T):0.3, (F,F):0.4})\n",
    "    def test_onenode(self):\n",
    "        self.assertEqual(P(self.p1, T), 0.3)\n",
    "    def test_twonode(self):\n",
    "        self.assertEqual(P(self.c, F, {'p1':T, 'p2':F}), 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.003s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=2 errors=0 failures=0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tests_to_run = unittest.TestSuite()\n",
    "tests_to_run.addTest(Tests_Problem2(\"test_onenode\"))\n",
    "tests_to_run.addTest(Tests_Problem2(\"test_twonode\"))\n",
    "unittest.TextTestRunner().run(tests_to_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### (2b)\n",
    "\n",
    "Craft a function `get_prob(X, e, bn)` to return the **normalized** probability distribution of variable `X` in Bayes net `bn`, given the evidence `e`.  That is, return $P(X \\mid e)$. The arguments are:\n",
    "* `X` is some representation of the variable you are querying the probability distribution of. Either a string (the variable name from the `BayesNode` or a `BayesNode` object itself are good options.\n",
    "* `e` is some representation of the evidence your probability is conditioned on. When given an empty argument (or `None`) for `e`, `get_prob` should return the marginal distribution $P(X)$.\n",
    "* `bn` is your `BayesNet` object.\n",
    "\n",
    "You may do this using the `enumeration` algorithm from class (pseudocode is in the book), or by brute force (i.e., use a few `for` loops). Either way, you should be using your `BayesNet` object to keep track of all the nodes and relationships between nodes so your `get_prob` function knows these things.\n",
    "\n",
    "Suggest implementation is below, where we use the `PDF_discrete` class and its associated functions as we did in the Bayes Nets in class notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution:\n",
    "\n",
    "class PDF_discrete:\n",
    "    '''Define a discrete probability distribution function.'''\n",
    "\n",
    "    def __init__(self, varname='?', freqs=None):\n",
    "        '''Create a dictionary of values - frequency pairs,\n",
    "        then normalize the distribution to sum to 1.'''\n",
    "        self.prob = {}\n",
    "        self.varname = varname\n",
    "        self.values = []\n",
    "        if freqs:\n",
    "            for (v, p) in freqs.items():\n",
    "                self[v] = p\n",
    "        self.normalize()\n",
    "\n",
    "    def __getitem__(self, value):\n",
    "        '''Given a value, return P[value]'''\n",
    "        try:\n",
    "            return self.prob[value]\n",
    "        except KeyError:\n",
    "            return 0\n",
    "\n",
    "    def __setitem__(self, value, p):\n",
    "        '''Set P[value] = p, input argument if '''\n",
    "        if value not in self.values:\n",
    "            self.values.append(value)\n",
    "        self.prob[value] = p\n",
    "\n",
    "    def normalize(self):\n",
    "        '''Normalize the probability distribution and return it.\n",
    "        If the sum of PDF values is 0, then return a 0'''\n",
    "        total = sum(self.prob.values())\n",
    "        if not isclose(total, 1.0):\n",
    "            for value in self.prob:\n",
    "                self.prob[value] /= total\n",
    "        return self\n",
    "    \n",
    "def extend(s, var, val):\n",
    "    \"\"\"Copy the substitution s and extend it by setting var to val; return copy.\"\"\"\n",
    "    s2 = s.copy()\n",
    "    s2[var] = val\n",
    "    return s2\n",
    "\n",
    "def get_prob(X, e, bn):\n",
    "    '''Return the conditional probability distribution of variable X\n",
    "    given evidence e, from BayesNet bn. [Figure 14.9]'''\n",
    "    Q = PDF_discrete(X)\n",
    "    for xi in bn.find_values(X):\n",
    "        Q[xi] = enumerate_all(bn.variables, extend(e, X, xi), bn)\n",
    "    return Q.normalize()\n",
    "    \n",
    "def enumerate_all(variables, e, bn):\n",
    "    '''Return the sum of those entries in P(variables | e{others})\n",
    "    consistent with e, where P is the joint distribution represented\n",
    "    by bn, and e{others} means e restricted to bn's other variables\n",
    "    (the ones other than variables). Parents must precede children in variables.'''\n",
    "    if not variables:\n",
    "        return 1.0\n",
    "    Y, rest = variables[0], variables[1:]\n",
    "    Ynode = bn.find_node(Y)\n",
    "    if Y in e:\n",
    "        # Y in evidence, so we know its value and just multiply\n",
    "        \n",
    "        return P(Ynode, e[Y], e) * enumerate_all(rest, e, bn)\n",
    "    else:\n",
    "        # Y not in evidence so we have to sum (Law of Total Prob.)    \n",
    "        return sum(P(Ynode, y, e) * enumerate_all(rest, extend(e, Y, y), bn)\n",
    "                   for y in bn.find_values(Y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2c)\n",
    "Use your `get_prob` function to calculate the following probabilities. Print them to the screen and compare to the original Bayes net figure given to make sure the output passes these \"unit tests\".\n",
    "\n",
    "1. The marginal probability of `Family History` is $P(FH=T)=0.15$\n",
    "2. The probability of *not* experiencing `Angina Pectoris`, given `Heart Disease` is observed, is $P(Ang=F \\mid HD=T)=1-0.85=0.15$\n",
    "3. The probability of `High Blood Pressure`, given a person does `Smoke and/or use Alcohol` but does not get `Moderate Exercise`, is $P(HBP=T \\mid Sm=T, ME=F)=0.72$\n",
    "4. The probability of an arbitrary individual having Heart Disease,  $P(HD=T)$\n",
    "5. The probability that an individual does not have Heart Disease, given that Rapid Heartbeat was observed,  \n",
    "$P(HD=F∣Rapid=T)$\n",
    "6. The probability that an individual is a `Smoker/Alcohol User` if they have `Heart Disease`, $P(Sm=T \\mid HD=T)$\n",
    "7. How would you expect the probability in 6. to change if you also know the individual has `High Blood Pressure`?  Verify your hypothesis by calculating the relevant probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{True: 0.2163440784303391, False: 0.7836559215696609}\n",
      "{True: 0.28205128205128205, False: 0.717948717948718}\n"
     ]
    }
   ],
   "source": [
    "p1 = get_prob(X='FamilyHistory', e={}, bn=heartDiseaseNet)\n",
    "p2 = get_prob(X='AnginaPectoris', e={'HeartDisease': T}, bn=heartDiseaseNet)\n",
    "p3 = get_prob(X='HighBloodPressure', e={'SmokingAndAlcohol': T, 'ModerateExercise': F}, bn=heartDiseaseNet)\n",
    "p4 = get_prob(X='HeartDisease', e={}, bn=heartDiseaseNet)\n",
    "p5 = get_prob(X='HeartDisease', e={'RapidHeartbeat': T}, bn=heartDiseaseNet)\n",
    "p6 = get_prob(X='SmokingAndAlcohol', e={'HeartDisease': T}, bn=heartDiseaseNet)\n",
    "p7 = get_prob(X='SmokingAndAlcohol', e={'HeartDisease': T, 'HighBloodPressure': T}, bn=heartDiseaseNet)\n",
    "print(p6.prob)\n",
    "print(p7.prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would expect it to be more likely that the individual is a smoker or alcohol user if they also have high blood pressure along with heart disease. This hypothesis is confirmed above in the print statements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2d)\n",
    "Rather than exact calculations, we can also *simulate* on a Bayesian Network.  Simulate 10000 hypothetical elderly individuals from South Carolina on the given network.  Using logicals, compute the probabilities in numbers (6.) and (7.) of part (2c) and verify that they are approximately equivalent.\n",
    "\n",
    "No API is required here, but your final result should print the empirical (simulated) probabilities next to the exact theoretical results for these two outcomes from (2c)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, False, True, False, False, True, True, True]\n"
     ]
    }
   ],
   "source": [
    "#Recommended simulation structure:\n",
    "#Set up same BayesNodes or Conditional Probability Tables as in (2a)\n",
    "\n",
    "#For 10000 samples...\n",
    "\n",
    "    #Randomly sample variables from top-to-bottom on the network, where children probabilities depend on parent values\n",
    "\n",
    "    #Save them all in one large Data frame or array\n",
    "citizens = []\n",
    "for i in range(10000):\n",
    "    prob_smoker = get_prob(X='SmokingAndAlcohol', e={}, bn=heartDiseaseNet)\n",
    "    smoker = np.random.choice([True, False], p = [prob_smoker.prob[1], prob_smoker.prob[0]])\n",
    "    prob_exercise = get_prob(X='ModerateExercise', e={}, bn=heartDiseaseNet)\n",
    "    exercise = np.random.choice([True, False], p = [prob_exercise.prob[1], prob_exercise.prob[0]])\n",
    "    if smoker == True:\n",
    "        if exercise == True:\n",
    "            prob_high_BP = get_prob(X='HighBloodPressure', e={'SmokingAndAlcohol': T, 'ModerateExercise': T}, bn=heartDiseaseNet)\n",
    "            high_BP = np.random.choice([True, False], p = [prob_high_BP.prob[1], prob_high_BP.prob[0]])\n",
    "        else:\n",
    "            prob_high_BP = get_prob(X='HighBloodPressure', e={'SmokingAndAlcohol': T, 'ModerateExercise': F}, bn=heartDiseaseNet)\n",
    "            high_BP = np.random.choice([True, False], p = [prob_high_BP.prob[1], prob_high_BP.prob[0]])\n",
    "    else:\n",
    "        if exercise == True:\n",
    "            prob_high_BP = get_prob(X='HighBloodPressure', e={'SmokingAndAlcohol': F, 'ModerateExercise': T}, bn=heartDiseaseNet)\n",
    "            high_BP = np.random.choice([True, False], p = [prob_high_BP.prob[1], prob_high_BP.prob[0]])\n",
    "        else:\n",
    "            prob_high_BP = get_prob(X='HighBloodPressure', e={'SmokingAndAlcohol': F, 'ModerateExercise': F}, bn=heartDiseaseNet)\n",
    "            high_BP = np.random.choice([True, False], p = [prob_high_BP.prob[1], prob_high_BP.prob[0]])\n",
    "    prob_atherosclerosis = get_prob(X='Atherosclerosis', e={}, bn=heartDiseaseNet)\n",
    "    atherosclerosis = np.random.choice([True, False], p = [prob_atherosclerosis.prob[1], prob_atherosclerosis.prob[0]])\n",
    "    prob_FH = get_prob(X='FamilyHistory', e={}, bn=heartDiseaseNet)\n",
    "    FH = np.random.choice([True, False], p = [prob_FH.prob[1], prob_FH.prob[0]])\n",
    "    if atherosclerosis == True:\n",
    "        if high_BP == True:\n",
    "            if FH == True:\n",
    "                prob_HD = get_prob(X='HeartDisease', e={'Atherosclerosis': T, 'HighBloodPressure': T, 'FamilyHistory': T}, bn=heartDiseaseNet)\n",
    "                HD = np.random.choice([True, False], p = [prob_HD.prob[1], prob_HD.prob[0]])\n",
    "            else:\n",
    "                prob_HD = get_prob(X='HeartDisease', e={'Atherosclerosis': T, 'HighBloodPressure': T, 'FamilyHistory': F}, bn=heartDiseaseNet)\n",
    "                HD = np.random.choice([True, False], p = [prob_HD.prob[1], prob_HD.prob[0]])\n",
    "        else:\n",
    "            if FH == True:\n",
    "                prob_HD = get_prob(X='HeartDisease', e={'Atherosclerosis': T, 'HighBloodPressure': F, 'FamilyHistory': T}, bn=heartDiseaseNet)\n",
    "                HD = np.random.choice([True, False], p = [prob_HD.prob[1], prob_HD.prob[0]])\n",
    "            else:\n",
    "                prob_HD = get_prob(X='HeartDisease', e={'Atherosclerosis': T, 'HighBloodPressure': F, 'FamilyHistory': F}, bn=heartDiseaseNet)\n",
    "                HD = np.random.choice([True, False], p = [prob_HD.prob[1], prob_HD.prob[0]])\n",
    "    elif atherosclerosis == False:\n",
    "        if high_BP == True:\n",
    "            if FH == True:\n",
    "                prob_HD = get_prob(X='HeartDisease', e={'Atherosclerosis': F, 'HighBloodPressure': T, 'FamilyHistory': T}, bn=heartDiseaseNet)\n",
    "                HD = np.random.choice([True, False], p = [prob_HD.prob[1], prob_HD.prob[0]])\n",
    "            else:\n",
    "                prob_HD = get_prob(X='HeartDisease', e={'Atherosclerosis': F, 'HighBloodPressure': T, 'FamilyHistory': F}, bn=heartDiseaseNet)\n",
    "                HD = np.random.choice([True, False], p = [prob_HD.prob[1], prob_HD.prob[0]])\n",
    "        else:\n",
    "            if FH == True:\n",
    "                prob_HD = get_prob(X='HeartDisease', e={'Atherosclerosis': F, 'HighBloodPressure': F, 'FamilyHistory': T}, bn=heartDiseaseNet)\n",
    "                HD = np.random.choice([True, False], p = [prob_HD.prob[1], prob_HD.prob[0]])\n",
    "            else:\n",
    "                prob_HD = get_prob(X='HeartDisease', e={'Atherosclerosis': F, 'HighBloodPressure': F, 'FamilyHistory': F}, bn=heartDiseaseNet)\n",
    "                HD = np.random.choice([True, False], p = [prob_HD.prob[1], prob_HD.prob[0]])\n",
    "    if HD == True:\n",
    "        prob_AP = get_prob(X='AnginaPectoris', e={'HeartDisease': T}, bn=heartDiseaseNet)\n",
    "        AP = np.random.choice([True, False], p = [prob_AP.prob[1], prob_AP.prob[0]])\n",
    "        prob_RH = get_prob(X='RapidHeartbeats', e={'HeartDisease': T}, bn=heartDiseaseNet)\n",
    "        RH = np.random.choice([True, False], p = [prob_AP.prob[1], prob_AP.prob[0]])\n",
    "    else:\n",
    "        prob_AP = get_prob(X='AnginaPectoris', e={'HeartDisease': F}, bn=heartDiseaseNet)\n",
    "        AP = np.random.choice([True, False], p = [prob_AP.prob[1], prob_AP.prob[0]])\n",
    "        prob_RH = get_prob(X='RapidHeartbeats', e={'HeartDisease': F}, bn=heartDiseaseNet)\n",
    "        RH = np.random.choice([True, False], p = [prob_AP.prob[1], prob_AP.prob[0]])\n",
    "print(citizens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated probabilities: 0.2181187820319566 0.2854881266490765\n",
      "Theorhetical results: {True: 0.2163440784303391, False: 0.7836559215696609} {True: 0.28205128205128205, False: 0.717948717948718}\n"
     ]
    }
   ],
   "source": [
    "HD_count = 0\n",
    "SM_and_HD_count = 0\n",
    "SM_HD_HBP_count = 0\n",
    "HD_and_HBP_count = 0\n",
    "for i in range(10000):\n",
    "    if citizens[i][5] == True:\n",
    "        HD_count += 1\n",
    "        if citizens[i][0] == True:\n",
    "            SM_and_HD_count += 1\n",
    "            if citizens[i][2] == True:\n",
    "                SM_HD_HBP_count += 1\n",
    "        if citizens[i][2] == True:\n",
    "            HD_and_HBP_count += 1\n",
    "print(\"Simulated probabilities:\", SM_and_HD_count/HD_count, SM_HD_HBP_count/HD_and_HBP_count)\n",
    "print(\"Theorhetical results:\", p6.prob, p7.prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
